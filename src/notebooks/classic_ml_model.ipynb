{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a3ed5a-6d10-4b7b-8529-d8072b8cfd2c",
   "metadata": {},
   "source": [
    "# Using classic machine learning models for movement pattern recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e350535-536e-4540-8ed3-a3c82b0f4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a7c72-5943-48b7-8634-e23a3efb3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/dataframes/labels_and_coordinates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1010f2-9dea-4e5c-91ac-b80232c8e609",
   "metadata": {},
   "source": [
    "# 1. Training models on all boulder data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b76ac4-090b-4188-9fda-2fd17a25c718",
   "metadata": {},
   "source": [
    "## Preprocessing and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbcbbd-10a4-483f-97ec-4b0cc363ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['frame', 'label'])\n",
    "y = data['label']\n",
    "\n",
    "# Encode categorical features\n",
    "encoder = LabelEncoder()\n",
    "X['boulder'] = encoder.fit_transform(X['boulder'])\n",
    "X['camera'] = encoder.fit_transform(X['camera'])\n",
    "X['participant'] = encoder.fit_transform(X['participant'])\n",
    "X['repetition'] = encoder.fit_transform(X['repetition'])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299b0d5-f722-4b74-be9b-9d710a971c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b5c31-9e3a-494c-b84a-4bf86e19e776",
   "metadata": {},
   "source": [
    "## Models used: Logistic Regression, Decision Tree, KNN, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2bb77-8df3-4a20-9b44-8ef7e4e042bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),  \n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdcc17d-fdae-4e7d-b48f-49c3119275e9",
   "metadata": {},
   "source": [
    "## Plotting evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e3fe5-d410-44ff-9017-6e6aa7f42759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics for each model\n",
    "metrics = {\n",
    "    \"Logistic Regression\": [0.50, 0.29, 0.50, 0.36],\n",
    "    \"Decision Tree\": [0.92, 0.92, 0.92, 0.92],\n",
    "    \"KNN\": [0.94, 0.94, 0.94, 0.94],\n",
    "    \"Random Forest\": [0.97, 0.97, 0.97, 0.97]\n",
    "}\n",
    "\n",
    "# Define the metrics labels\n",
    "metric_labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "\n",
    "# Plot the metrics for each model\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "\n",
    "teal_colors = ['#008080', '#009090', '#00A0A0', '#00B0B0']  # Teal color\n",
    "\n",
    "for i, (name, metric_values) in enumerate(metrics.items()):\n",
    "    ax = axes[i]\n",
    "    ax.bar(metric_labels, metric_values, color=teal_colors)\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylim(0, 1)  # Setting y-axis limit to [0, 1] for better visualization\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7aabe-0805-4813-81e9-18c560ac9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, metric_values in metrics.items():\n",
    "    print(f\"{name}: {metric_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9382b-f7a0-4a31-b851-bd22bc8ef6f1",
   "metadata": {},
   "source": [
    "# 2. Training models with more preprocessing\n",
    "- using only boulder W3 and W4\n",
    "- dropping \"no_movement_of_interest\" and other labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b3856-339c-41a4-a470-134fe8122dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- basic filtering of boulders and labels that are not of interest -----------\n",
    "# Filter rows by boulder type\n",
    "data = data[data['boulder'].isin(['W3', 'W4'])]\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Drop irrelevant labels\n",
    "data = data[~data['label'].isin(['no_movement_of_interest', 'before_start_position', 'start_position'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c567b6-9298-439e-a4b8-dd74afd7536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values from 'boulder' column\n",
    "unique_boulder_values = data['boulder'].unique()\n",
    "print(\"Unique values in 'boulder' column:\", unique_boulder_values)\n",
    "\n",
    "# unique values from 'label' column\n",
    "unique_label_values = data['label'].unique()\n",
    "print(\"Unique values in 'label' column:\", unique_label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c646c-e4b3-44ed-be1f-cfd97b091609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------- some preprocessing -----------------------\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['frame', 'label'])\n",
    "y = data['label']\n",
    "\n",
    "# Apply a rolling average to smooth sensor data\n",
    "sensor_columns = X.columns[7:]  # Adjust index if needed\n",
    "X[sensor_columns] = X[sensor_columns].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Define categorical and numeric features\n",
    "categorical_features = ['boulder', 'camera', 'participant', 'repetition']\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "# Preprocessor: encode categorical features and pass through numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split the dataset into training and testing sets before SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing to training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b1517-d958-4b1e-86cc-93388a02eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# uncomment to use GrisSearch later on\n",
    "# Define a pipeline and grid search for each model\n",
    "param_grid = {\n",
    "    \"Logistic Regression\": {'classifier__C': [0.01, 0.1, 1, 10, 100]},\n",
    "    \"Decision Tree\": {'classifier__max_depth': [None, 10, 20, 30, 40, 50]},\n",
    "    \"KNN\": {'classifier__n_neighbors': [3, 5, 7, 9]},\n",
    "    \"Random Forest\": {'classifier__n_estimators': [50, 100, 200], 'classifier__max_depth': [None, 10, 20, 30]}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bb98c-845c-437c-8cbd-26818e550ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('classifier', model)])\n",
    "\n",
    "    \"\"\"\n",
    "    # Uncomment these lines to use GridSearchCV later\n",
    "    grid_search = GridSearchCV(pipeline, param_grid[name], cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "    print(f\"Training {name}...\")\n",
    "    grid_search.fit(X_res, y_res)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    y_pred = grid_search.predict(X_test_preprocessed)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Training {name}...\")\n",
    "    pipeline.fit(X_res, y_res)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    y_pred = pipeline.predict(X_test_preprocessed)\n",
    "    \n",
    "    print(f\"Evaluating {name}...\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0fc2a-d92a-481c-8be0-6c4555f2acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics for each model\n",
    "metrics = {\n",
    "    \"Logistic Regression\": [0.83, 0.79, 0.89, 0.83],\n",
    "    \"Decision Tree\": [0.93, 0.93, 0.93, 0.93],\n",
    "    \"KNN\": [0.94, 0.94, 0.98, 0.95],\n",
    "    \"Random Forest\": [0.98, 0.97, 0.96, 0.97]\n",
    "}\n",
    "\n",
    "# Define the metrics labels\n",
    "metric_labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "\n",
    "# Plot the metrics for each model\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "\n",
    "teal_colors = ['#008080', '#009090', '#00A0A0', '#00B0B0']  # Teal color\n",
    "\n",
    "for i, (name, metric_values) in enumerate(metrics.items()):\n",
    "    ax = axes[i]\n",
    "    ax.bar(metric_labels, metric_values, color=teal_colors)\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylim(0, 1)  # Setting y-axis limit to [0, 1] for better visualization\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188790bb-f15a-470b-9e6c-4a5de0eba4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(y_test.unique()), yticklabels=sorted(y_test.unique()))\n",
    "plt.title(f'Confusion Matrix for {name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8de68-987d-4db5-8cd2-4247aabeaa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique label\n",
    "label_counts = data['label'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(label_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
