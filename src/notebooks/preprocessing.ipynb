{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/dataframes/labels_and_coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Making some data preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Dropping NaN columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many frames are there before any preprocessing\n",
    "print(f\"\\nTotal number of frames before dropping NaN values: {df.shape[0]}\")\n",
    "\n",
    "# dropping all the colums with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# how many frames are left\n",
    "print(f\"\\nTotal number of frames after dropping NaN values: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Calculate COM, knee and elbow angle\n",
    "Goal: adding 'com_x', 'com_y', 'left_elbow_angle', 'right_elbow_angle', 'left_knee_angle', 'right_knee_angle' per frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center of mass calculation\n",
    "def calculate_com(df):\n",
    "    df['com_x'] = (\n",
    "        0.532*df['left_hip_x'] + 0.1175*df['left_knee_x'] + 0.1175*df['right_knee_x'] + 0.0535*df['left_ankle_x'] \n",
    "        + 0.0535*df['right_ankle_x'] + 0.0133*df['left_foot_x'] + 0.0133*df['right_foot_x'] + 0.029*df['left_shoulder_x'] \n",
    "        + 0.029*df['right_shoulder_x'] + 0.0157*df['left_elbow_x'] + 0.0157*df['right_elbow_x'] + 0.005*df['left_wrist_x'] \n",
    "        + 0.005*df['right_wrist_x']\n",
    "    )\n",
    "\n",
    "    df['com_y'] = (\n",
    "        0.532*df['left_hip_y'] + 0.1175*df['left_knee_y'] + 0.1175*df['right_knee_y'] + 0.0535*df['left_ankle_y'] \n",
    "        + 0.0535*df['right_ankle_y'] + 0.0133*df['left_foot_y'] + 0.0133*df['right_foot_y'] + 0.029*df['left_shoulder_y'] \n",
    "        + 0.029*df['right_shoulder_y'] + 0.0157*df['left_elbow_y'] + 0.0157*df['right_elbow_y'] + 0.005*df['left_wrist_y'] \n",
    "        + 0.005*df['right_wrist_y']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Define the angle calculation\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    a = np.array(p1) - np.array(p2)\n",
    "    b = np.array(p3) - np.array(p2)\n",
    "    \n",
    "    cosine_angle = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    \n",
    "    return np.degrees(angle)\n",
    "\n",
    "\n",
    "# Apply the angle calculation to the DataFrame: elbow and knee angles\n",
    "def add_angles_to_df(df):\n",
    "    df['left_elbow_angle'] = df.apply(lambda row: calculate_angle(\n",
    "        [row['left_shoulder_x'], row['left_shoulder_y']],\n",
    "        [row['left_elbow_x'], row['left_elbow_y']],\n",
    "        [row['left_wrist_x'], row['left_wrist_y']]\n",
    "    ), axis=1)\n",
    "\n",
    "    df['right_elbow_angle'] = df.apply(lambda row: calculate_angle(\n",
    "        [row['right_shoulder_x'], row['right_shoulder_y']],\n",
    "        [row['right_elbow_x'], row['right_elbow_y']],\n",
    "        [row['right_wrist_x'], row['right_wrist_y']]\n",
    "    ), axis=1)\n",
    "\n",
    "    df['left_knee_angle'] = df.apply(lambda row: calculate_angle(\n",
    "        [row['left_hip_x'], row['left_hip_y']],\n",
    "        [row['left_knee_x'], row['left_knee_y']],\n",
    "        [row['left_ankle_x'], row['left_ankle_y']]\n",
    "    ), axis=1)\n",
    "\n",
    "    df['right_knee_angle'] = df.apply(lambda row: calculate_angle(\n",
    "        [row['right_hip_x'], row['right_hip_y']],\n",
    "        [row['right_knee_x'], row['right_knee_y']],\n",
    "        [row['right_ankle_x'], row['right_ankle_y']]\n",
    "    ), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the center of mass\n",
    "df = calculate_com(df)\n",
    "\n",
    "# Add the angles to the DataFrame\n",
    "df = add_angles_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Calculating velocity and acceleration\n",
    "**calculated per boulder per athlete!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['participant'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['boulder'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_velocity_acceleration(df):\n",
    "    # Group by participant and boulder\n",
    "    grouped = df.groupby(['participant', 'boulder'])\n",
    "\n",
    "    # Calculate velocities\n",
    "    df['com_vx'] = grouped['com_x'].diff() / grouped['time(s)'].diff()\n",
    "    df['com_vy'] = grouped['com_y'].diff() / grouped['time(s)'].diff()\n",
    "\n",
    "    # Calculate accelerations\n",
    "    df['com_ax'] = grouped['com_vx'].diff() / grouped['time(s)'].diff()\n",
    "    df['com_ay'] = grouped['com_vy'].diff() / grouped['time(s)'].diff()\n",
    "\n",
    "    # Handle first frame for each participant and boulder\n",
    "    first_frames = df.groupby(['participant', 'boulder']).head(1).index\n",
    "    df.loc[first_frames, ['com_vx', 'com_vy', 'com_ax', 'com_ay']] = 0  # Or set to NaN if initial conditions are unknown\n",
    "\n",
    "    # Handle last frame for each participant and boulder\n",
    "    for name, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            last_index = group.index[-1]\n",
    "            second_last_index = group.index[-2]\n",
    "            df.loc[last_index, ['com_vx', 'com_vy', 'com_ax', 'com_ay']] = df.loc[second_last_index, ['com_vx', 'com_vy', 'com_ax', 'com_ay']]\n",
    "        else:\n",
    "            df.loc[group.index[0], ['com_vx', 'com_vy', 'com_ax', 'com_ay']] = 0\n",
    "\n",
    "    # Fill any remaining NaN values with 0\n",
    "    df[['com_vx', 'com_vy', 'com_ax', 'com_ay']] = df[['com_vx', 'com_vy', 'com_ax', 'com_ay']].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_velocity_acceleration(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in specific columns\n",
    "nan_check = df[['com_vx', 'com_vy', 'com_ax', 'com_ay']].isna().any()\n",
    "\n",
    "# Print the result\n",
    "print(\"Columns with NaN values:\")\n",
    "print(nan_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for velocity and acceleration columns\n",
    "print(df[['com_vx', 'com_vy', 'com_ax', 'com_ay']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothing the velocity and acceleration data\n",
    "def smooth_data(df, columns, window_size=5, polyorder=2):\n",
    "    smoothed_df = df.copy()\n",
    "    for col in columns:\n",
    "        smoothed_df[col] = savgol_filter(df[col], window_length=window_size, polyorder=polyorder)\n",
    "    return smoothed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the resultant velocity and acceleration \n",
    "def calculate_resultant_velocity_acceleration(df):\n",
    "    df['com_v'] = np.sqrt(df['com_vx']**2 + df['com_vy']**2)\n",
    "    df['com_a'] = np.sqrt(df['com_ax']**2 + df['com_ay']**2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_resultant_velocity_acceleration(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the data\n",
    "smoothed_columns = ['com_vx', 'com_vy', 'com_ax', 'com_ay', 'com_v', 'com_a']\n",
    "df = smooth_data(df, smoothed_columns, window_size=11, polyorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the specified participant and boulder\n",
    "participant = 'Janja Garnbret'\n",
    "boulder = 'W3'\n",
    "filtered_df = df[(df['participant'] == participant) & (df['boulder'] == boulder)]\n",
    "\n",
    "# Plot the resultant velocity and acceleration\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(filtered_df['time(s)'], filtered_df['com_v'], label='Velocity')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Velocity')\n",
    "plt.title(f'Resultant Velocity for {participant} on {boulder}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(filtered_df['time(s)'], filtered_df['com_a'], label='Acceleration')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Acceleration')\n",
    "plt.title(f'Resultant Acceleration for {participant} on {boulder}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/dataframes/labels_and_coordinates_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Looking at visibility and presence per boulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to calculate average visibility and presence\n",
    "def calculate_average_visibility_presence(df, boulder_id, landmarks):\n",
    "    boulder_df = df[df['boulder'] == boulder_id]\n",
    "    \n",
    "    results = {}\n",
    "    for landmark in landmarks:\n",
    "        visibility_col = f'{landmark}_v'\n",
    "        presence_col = f'{landmark}_p'\n",
    "        \n",
    "        avg_visibility = boulder_df[visibility_col].mean()\n",
    "        avg_presence = boulder_df[presence_col].mean()\n",
    "        \n",
    "        results[landmark] = {\n",
    "            'average_visibility': avg_visibility,\n",
    "            'average_presence': avg_presence\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define the landmarks you are interested in\n",
    "landmarks = ['left_knee', 'right_knee', 'left_ankle', 'right_ankle']\n",
    "\n",
    "# List of boulders to analyze\n",
    "boulders = df['boulder'].unique()\n",
    "\n",
    "# Calculate the averages for each boulder\n",
    "boulder_averages = {}\n",
    "for boulder in boulders:\n",
    "    boulder_averages[boulder] = calculate_average_visibility_presence(df, boulder, landmarks)\n",
    "\n",
    "# Print the results\n",
    "for boulder, averages in boulder_averages.items():\n",
    "    print(f\"Boulder: {boulder}\")\n",
    "    for landmark, values in averages.items():\n",
    "        print(f\"  {landmark}: Average Visibility = {values['average_visibility']}, Average Presence = {values['average_presence']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
