{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24233e7a-3ce7-4aed-8f61-be3eed4615f2",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network for movement pattern recognition\n",
    "\n",
    "To design a model that learns and predicts movement patterns accurately based on the provided dataset, we need to leverage the temporal nature of the data.\n",
    "This typically involves using Recurrent Neural Networks (RNNs) or their more advanced variants like LSTMs and GRUs, which are well-suited for sequence data.\n",
    "Here Bidirectional LSTMs and Attention mechanisms to capture the dependencies in the sequences were used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48644d18-3ff0-4b04-83ad-0fbd336c8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, Attention, Concatenate, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1f27f-f408-4288-bc1e-c85e75a6b1c2",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159bf54-9bbd-4252-9298-7243f5328762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/dataframes/labels_and_coordinates_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b66516-4df2-4190-aa71-cec68c5ee087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f3391-7ab0-46f9-af3c-d3ccc7857d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Normalize keypoint data\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Gather all keypoint columns (all columns with a \"_x\", \"_y\", \"_z\", \"_v\", \"_p\", \"com\" or \"angle\" in their name)\n",
    "keypoint_columns = [col for col in data.columns if '_x' in col or '_y' in col or '_z' in col or '_v' in col or '_p' in col or 'com' in col or 'angle' in col]\n",
    "# Apply fit_transform to keypoint column data only\n",
    "data[keypoint_columns] = scaler.fit_transform(data[keypoint_columns])\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "# pd.get_dummies(...) converts categorical variable into dummy/indicator variables (https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
    "data = pd.get_dummies(data, columns=['boulder', 'camera', 'participant', 'repetition'])\n",
    "\n",
    "# Encode labels\n",
    "if 'label' in data.columns:\n",
    "    label_encoder = LabelEncoder() # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "    data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Parameters for reshaping\n",
    "timesteps = 2 # Defines how many timesteps each sequence in the dataset will contain. For now it is set to 2, but we should try several options.\n",
    "total_features = data.drop('label', axis=1).shape[1] # Get nr of total features (= nr of features without the label column)\n",
    "\n",
    "# A check to ensure that each sequence fed into the model has a consistent shape\n",
    "if total_features % timesteps != 0:\n",
    "    raise ValueError(f\"Number of total features ({total_features}) is not divisible by defined timesteps ({timesteps}).\")\n",
    "features_per_timestep = total_features // timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f2244-2c7e-4cbc-8668-1e46ccc11709",
   "metadata": {},
   "source": [
    "## Split and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f6747-c3ba-4476-bb5e-6ad33e056799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "X = data.drop('label', axis=1).values.reshape(-1, timesteps, features_per_timestep)\n",
    "y = data['label'].values\n",
    "\n",
    "# We have to ensure the data types are compatible with TensorFlow\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int32)\n",
    "\n",
    "# The usual data split into train, test and validation sets...\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# ... and respective TensorFlow train, val and test datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145065b-a3a0-4adf-a6e2-9ca65b911272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(timesteps, features_per_timestep, nr_classes):\n",
    "    \"\"\"\n",
    "    This model contains bidirectional LSTMs and self-attention layers\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(timesteps, features_per_timestep))\n",
    "\n",
    "    # First Bidirectional LSTM layer with attention\n",
    "    x1 = Bidirectional(LSTM(64, return_sequences=True))(inputs)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    # Further reading about keras attention layers: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention\n",
    "    attention_layer_1 = Attention()([x1, x1])  # Self-attention on the first LSTM output\n",
    "\n",
    "    # Second Bidirectional LSTM layer with attention\n",
    "    x2 = Bidirectional(LSTM(128, return_sequences=True))(x1)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    attention_layer_2 = Attention()([x2, x2])  # Self-attention on the second LSTM output\n",
    "\n",
    "    # Third Bidirectional LSTM layer\n",
    "    x3 = Bidirectional(LSTM(64, return_sequences=False))(x2)  # No return_sequences to flatten LSTM output\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    # Concatenate attention outputs with the last LSTM layer output\n",
    "    concatenated = Concatenate()([Flatten()(attention_layer_1), Flatten()(attention_layer_2), x3])\n",
    "\n",
    "    # Dense layers after concatenation to learn from both the LSTM and attention outputs\n",
    "    x_final = Dense(128, activation='relu')(concatenated)\n",
    "    x_final = Dropout(0.3)(x_final)\n",
    "    x_final = Dense(64, activation='relu')(x_final)\n",
    "    outputs = Dense(nr_classes, activation='softmax')(x_final)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54726c0c-6023-4b9d-9b48-7eb17f7caf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(timesteps, features_per_timestep, len(np.unique(y)))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dad270-e17e-4f07-8443-bd984e7cbaec",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08ec44-aebe-46a8-86de-5a0499d66e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy}, Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bca25-f5e4-457d-b3ed-05bf287bbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Extracting history data\n",
    "history_dict = history.history\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history_dict['accuracy'], 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, history_dict['val_accuracy'], 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history_dict['loss'], 'bo', label='Training loss')\n",
    "plt.plot(epochs, history_dict['val_loss'], 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c568f0-ae81-4065-93c0-d4bbef2286bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict the labels for the test dataset\n",
    "y_pred = model.predict(test_dataset)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Map numeric labels to their corresponding names\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "\n",
    "# Get unique labels\n",
    "unique_labels = np.unique(np.concatenate((y_test_labels, y_pred_labels)))\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(unique_labels), yticklabels=sorted(unique_labels))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7451a0-f3c8-44f5-90e7-d42dcba3892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Normalize the confusion matrix by row (true labels)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_normalized = np.round(cm_normalized, 2)  # Round to 2 decimal places\n",
    "\n",
    "# Display the normalized confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=label_encoder.classes_)\n",
    "fig, ax = plt.subplots(figsize=(14, 14))  # Increase figure size for better readability\n",
    "disp.plot(xticks_rotation='vertical', ax=ax, cmap='viridis')  # Choose a colormap for better contrast\n",
    "\n",
    "# Adjust font size\n",
    "plt.xticks(fontsize=10, ha='center')\n",
    "plt.yticks(fontsize=10, va='center')\n",
    "\n",
    "# Update text properties in the matrix\n",
    "for text in disp.text_.ravel():\n",
    "    text.set_fontsize(10)  # Set font size for the numbers\n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Add padding to ensure elements are not overlapping\n",
    "\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
