{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b62104e-dc59-480c-95f7-79a343b3228e",
   "metadata": {},
   "source": [
    "# Plots for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bbce25-4da9-4276-9eae-2e2a3277da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dropout, Attention, Concatenate, Dense, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f3797-c250-4e64-b8e7-0aad0507d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../data/dataframes/labels_and_coordinates_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b99be6-6249-432c-971a-723b554c038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_classic_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    # Define the manual mappings for each categorical column\n",
    "    boulder_mapping = {'W1': 1, 'W2': 2, 'W3': 3, 'W4': 4}\n",
    "    camera_mapping = {'Cam21': 21, 'Cam22': 22, 'Cam24': 24}\n",
    "    participant_mapping = {\n",
    "        'Ai Mori': 1, 'Anastasia Sanders': 2, 'Ayala Kerem': 3, 'Brooke Raboutou': 4,\n",
    "        'Chaehyun Seo': 5, 'Helene Janicot': 6, 'Jain Kim': 7, 'Janja Garnbret': 8,\n",
    "        'Jessica Pilz': 9, 'Kyra Condie': 10, 'Laura Rogora': 11, 'Manon Hily': 12,\n",
    "        'Mia Krampl': 13, 'Miho Nonaka': 14, 'Molly Thompsonsmith': 15,\n",
    "        'Natalia Grossman': 16, 'Oceania Mackenzie': 17, 'Oriane Bertone': 18,\n",
    "        'Vita Lukan': 19, 'Yejoo Seo': 20, 'Zelia Avezou': 21\n",
    "    }\n",
    "    repetition_mapping = {'V1': 1, 'V2': 2, 'V3': 3, 'V4': 4, 'V5': 5, 'V6': 6, 'V7': 7, 'V8': 8, 'V9': 9, 'V10': 10}\n",
    "\n",
    "    # Map the categorical columns using the defined mappings\n",
    "    data['boulder'] = data['boulder'].map(boulder_mapping)\n",
    "    data['camera'] = data['camera'].map(camera_mapping)\n",
    "    data['participant'] = data['participant'].map(participant_mapping)\n",
    "    data['repetition'] = data['repetition'].map(repetition_mapping)\n",
    "\n",
    "    return data, participant_mapping\n",
    "\n",
    "\n",
    "def split_data_boulder_specific(data):\n",
    "    train_boulders = [1, 2, 4]\n",
    "    test_boulders = [3]\n",
    "\n",
    "    X_train = data[data['boulder'].isin(train_boulders)]\n",
    "    y_train = X_train.pop('label')\n",
    "    X_test = data[data['boulder'].isin(test_boulders)]\n",
    "    y_test = X_test.pop('label')\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def split_data_athlete_specific(data, participant_mapping):\n",
    "    test_athletes = ['Ai Mori', 'Brooke Raboutou', 'Oceania Mackenzie', 'Mia Krampl']\n",
    "    test_athlete_ids = [participant_mapping[athlete] for athlete in test_athletes]\n",
    "\n",
    "    X_train = data[~data['participant'].isin(test_athlete_ids)]\n",
    "    y_train = X_train.pop('label')\n",
    "    X_test = data[data['participant'].isin(test_athlete_ids)]\n",
    "    y_test = X_test.pop('label')\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def evaluate_classic_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier()\n",
    "    }\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name} model...\")\n",
    "        if name == \"Logistic Regression\":\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        results[name] = {\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "            'Recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "            'F1 Score': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        }\n",
    "        print(f\"{name} results: {results[name]}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def preprocess_rnn_data(data):\n",
    "    # Remove missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Normalize keypoint data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Gather all keypoint columns\n",
    "    keypoint_columns = [col for col in data.columns if '_x' in col or '_y' in col or '_z' in col or '_v' in col or '_p' in col or 'com' in col or 'angle' in col]\n",
    "    data[keypoint_columns] = scaler.fit_transform(data[keypoint_columns])\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    data = pd.get_dummies(data, columns=['boulder', 'camera', 'participant', 'repetition'])\n",
    "\n",
    "    # Encode labels\n",
    "    if 'label' in data.columns:\n",
    "        label_encoder = LabelEncoder() \n",
    "        data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "    return data, label_encoder\n",
    "\n",
    "\n",
    "def split_rnn_data(data, split_by_boulder=True):\n",
    "    if split_by_boulder:\n",
    "        train_data = data[data['boulder_W3'] == 0]\n",
    "        test_data = data[data['boulder_W3'] == 1]\n",
    "        \n",
    "    else:\n",
    "        test_athletes = [\"participant_Ai Mori\", \"participant_Brooke Raboutou\", \"participant_Oceania Mackenzie\", \"participant_Mia Krampl\"]\n",
    "        test_data = data[data[test_athletes].any(axis=1)]\n",
    "        train_data = data[~data[test_athletes].any(axis=1)]\n",
    "\n",
    "    timesteps = 2\n",
    "    total_features = data.drop('label', axis=1).shape[1]\n",
    "    if total_features % timesteps != 0:\n",
    "        raise ValueError(f\"Number of total features ({total_features}) is not divisible by defined timesteps ({timesteps}).\")\n",
    "    features_per_timestep = total_features // timesteps\n",
    "\n",
    "    X_train = train_data.drop('label', axis=1).values.reshape(-1, timesteps, features_per_timestep).astype(np.float32)\n",
    "    y_train = train_data['label'].values.astype(np.int32)\n",
    "    X_test = test_data.drop('label', axis=1).values.reshape(-1, timesteps, features_per_timestep).astype(np.float32)\n",
    "    y_test = test_data['label'].values.astype(np.int32)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n",
    "    return train_dataset, test_dataset, len(np.unique(y_train))\n",
    "\n",
    "\n",
    "def create_rnn_model(timesteps, features_per_timestep, nr_classes):\n",
    "    inputs = Input(shape=(timesteps, features_per_timestep))\n",
    "    x1 = Bidirectional(LSTM(64, return_sequences=True))(inputs)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "    attention_layer_1 = Attention()([x1, x1])\n",
    "    x2 = Bidirectional(LSTM(128, return_sequences=True))(x1)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "    attention_layer_2 = Attention()([x2, x2])\n",
    "    x3 = Bidirectional(LSTM(64, return_sequences=False))(x2)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "    concatenated = Concatenate()([Flatten()(attention_layer_1), Flatten()(attention_layer_2), x3])\n",
    "    x_final = Dense(128, activation='relu')(concatenated)\n",
    "    x_final = Dropout(0.3)(x_final)\n",
    "    x_final = Dense(64, activation='relu')(x_final)\n",
    "    outputs = Dense(nr_classes, activation='softmax')(x_final)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_evaluate_rnn_model(train_dataset, test_dataset, timesteps, features_per_timestep, nr_classes):\n",
    "    model = create_rnn_model(timesteps, features_per_timestep, nr_classes)\n",
    "    print(\"Training RNN model...\")\n",
    "    history = model.fit(train_dataset, epochs=10, verbose=1)\n",
    "    \n",
    "    # Evaluate on test dataset\n",
    "    y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "    y_pred_prob = model.predict(test_dataset)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"RNN model results - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}\")\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Predictions': y_pred,\n",
    "        'True Labels': y_true\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48608ca-63e0-4383-aede-04ce0bbc081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- main ----------------------------------\n",
    "# > > > > > > > > > > > > > > > > > > > > > CLASSIC ML < < < < < < < < < < < < < < < < < < < <\n",
    "# Preprocess data for the classic ml models\n",
    "data_classic, participant_mapping = preprocess_classic_data(filepath)\n",
    "\n",
    "# Boulder-specific split\n",
    "print(\"Evaluating models on Boulder-specific split...\")\n",
    "X_train_boulder, y_train_boulder, X_test_boulder, y_test_boulder = split_data_boulder_specific(data_classic)\n",
    "classic_results_boulder = evaluate_classic_models(X_train_boulder, y_train_boulder, X_test_boulder, y_test_boulder)\n",
    "\n",
    "# Athlete-specific split\n",
    "print(\"Evaluating models on Athlete-specific split...\")\n",
    "X_train_athlete, y_train_athlete, X_test_athlete, y_test_athlete = split_data_athlete_specific(data_classic, participant_mapping)\n",
    "classic_results_athlete = evaluate_classic_models(X_train_athlete, y_train_athlete, X_test_athlete, y_test_athlete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02d71e-e032-40fd-a661-ee6b47867bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# > > > > > > > > > > > > > > > > > > > > > RNN < < < < < < < < < < < < < < < < < < < <\n",
    "# Preprocess data for the rnn model\n",
    "data_rnn = pd.read_csv(filepath)\n",
    "data_rnn, label_encoder = preprocess_rnn_data(data_rnn)\n",
    "\n",
    "# Boulder-specific split for RNN\n",
    "print(\"Evaluating RNN on Boulder-specific split...\")\n",
    "train_dataset_boulder, test_dataset_boulder, nr_classes_boulder = split_rnn_data(data_rnn, split_by_boulder=True)\n",
    "rnn_results_boulder = train_evaluate_rnn_model(train_dataset_boulder, test_dataset_boulder, 2, data_rnn.drop('label', axis=1).shape[1] // 2, nr_classes_boulder)\n",
    "\n",
    "# Athlete-specific split for RNN\n",
    "print(\"Evaluating RNN on Athlete-specific split...\")\n",
    "train_dataset_athlete, test_dataset_athlete, nr_classes_athlete = split_rnn_data(data_rnn, split_by_boulder=False)\n",
    "rnn_results_athlete = train_evaluate_rnn_model(train_dataset_athlete, test_dataset_athlete, 2, data_rnn.drop('label', axis=1).shape[1] // 2, nr_classes_athlete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be73ac6-5aea-49f7-b993-2451729fece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance overview - plot\n",
    "# Define colors\n",
    "colors = ['#008080', '#20B2AA', '#FF8C00', '#FF6347']\n",
    "\n",
    "def plot_results(ax, results, title):\n",
    "    df = pd.DataFrame(results).T\n",
    "    df.plot(kind='bar', color=colors, ax=ax)\n",
    "    ax.set_ylim(0, 1)  # Set y-axis limits from 0 to 1\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_xticklabels(df.index, rotation=45)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n",
    "\n",
    "# Assuming classic_results_boulder and classic_results_athlete are defined as dictionaries\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot results for classic ML models\n",
    "plot_results(axes[0], classic_results_boulder, 'Model Performance on Boulder Test Set')\n",
    "plot_results(axes[1], classic_results_athlete, 'Model Performance on Athlete Test Set')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
